{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Parametertuningverbeterd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNjSL9Tt/Dl6hk8sBVsSKLg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7UsubxaQBolh","colab_type":"code","colab":{}},"source":["#Code originally ran on Google Colab using GPU provided by Google\n","\n","#Importing packages\n","import statistics\n","import copy \n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","#import matplotlib.pyplot as plt\n","\n","from tensorflow import keras\n","from sklearn.preprocessing import MinMaxScaler\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uoXG_lGBqvs","colab_type":"code","colab":{}},"source":["#Setting random seed\n","RANDOM_SEED = 2020\n","np.random.seed(RANDOM_SEED)\n","tf.random.set_seed(RANDOM_SEED)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhy87nbSB3Xt","colab_type":"code","outputId":"aa8c4ce6-0ce6-4ebd-9879-5a36d4abda7e","executionInfo":{"status":"ok","timestamp":1591962871722,"user_tz":-120,"elapsed":23505,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#Connecting to Google Drive\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aclMvabxY4n-","colab_type":"code","colab":{}},"source":["#Check GPU\n","#from tensorflow.python.client import device_lib\n","#device_lib.list_local_devices()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Kk0Sv6HB4LO","colab_type":"code","colab":{}},"source":["#Importing data from Google Drive into pandas dataframe while parsing dates as index\n","df = pd.read_csv(\"/content/gdrive/My Drive/Ethereum.csv\", parse_dates = [\"date\"], index_col = \"date\") #Change dataset name accordingly\n","df = df.sort_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvD9gvboB8C0","colab_type":"code","colab":{}},"source":["#removing unnecesarry index column left behind by R\n","df = df.drop([\"Unnamed: 0\"], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rr0jOGbFB-0V","colab_type":"code","colab":{}},"source":["#Creating a function that will return the large or big dataset\n","def featureSelector(crypto, size):\n","  articles = \"articles\" + crypto\n","  sentiment = \"sentiment\" + crypto\n","  trend = \"trend\" + crypto\n","  wiki = \"wiki\" + crypto\n","  if size not in [0, 1]:\n","    print(\"wrong size specification\")\n","    pass\n","\n","  elif size == 0: #small dataset\n","    return df.loc[:,[\"open\", \"high\", \"low\", \"close\", \"volume\", \"marketCap\", articles, sentiment, trend, wiki, #change articles, sentiment, trend and wiki accordingly\n","           \"wti\", \"brent\", \"EPU\", \"vixClose\", \"target\"]]\n","  else: #big dataset\n","    return df.loc[:,[\"open\", \"high\", \"low\", \"close\", \"volume\", \"marketCap\", articles, sentiment, \"articlesBlockchain\", \"sentimentBlockchain\", \"articlesCryptocurrency\", \"sentimentCryptocurrency\", #change articles, sentiment accordingly\n","           \"articlesCryptocurrencies\", \"sentimentCryptocurrencies\", trend, \"trendBlockchain\", \"trendCryptocurrency\", \"trendCryptocurrencies\", wiki, \"wikiBlockchain\", \"wikiCryptocurrency\", #change trend and wiki accordingly\n","           \"wti\", \"brent\", \"EPU\", \"vixClose\", \"target\"]]\n","\n","# datasetConstructor(\"Bitcoin\"/\"Ethereum\"/\"Ripple\", 0/1) where 0 is small dataset and 1 large\n","# in case of error: reread from csv \n","df = featureSelector(\"Ethereum\", 1)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"88MaP9aB40Vl","colab_type":"code","outputId":"46a17ba2-2877-4c6c-b3ef-e136e270d870","executionInfo":{"status":"ok","timestamp":1591973964184,"user_tz":-120,"elapsed":752,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["df.head()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>marketCap</th>\n","      <th>articlesEthereum</th>\n","      <th>sentimentEthereum</th>\n","      <th>articlesBlockchain</th>\n","      <th>sentimentBlockchain</th>\n","      <th>articlesCryptocurrency</th>\n","      <th>sentimentCryptocurrency</th>\n","      <th>articlesCryptocurrencies</th>\n","      <th>sentimentCryptocurrencies</th>\n","      <th>trendEthereum</th>\n","      <th>trendBlockchain</th>\n","      <th>trendCryptocurrency</th>\n","      <th>trendCryptocurrencies</th>\n","      <th>wikiEthereum</th>\n","      <th>wikiBlockchain</th>\n","      <th>wikiCryptocurrency</th>\n","      <th>wti</th>\n","      <th>brent</th>\n","      <th>EPU</th>\n","      <th>vixClose</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2017-01-01</th>\n","      <td>7.98</td>\n","      <td>8.47</td>\n","      <td>7.98</td>\n","      <td>8.17</td>\n","      <td>14731700.0</td>\n","      <td>715049208</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>10</td>\n","      <td>-1.380042</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1852</td>\n","      <td>2006</td>\n","      <td>2389</td>\n","      <td>52.36</td>\n","      <td>55.05</td>\n","      <td>2351</td>\n","      <td>12.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2017-01-02</th>\n","      <td>8.17</td>\n","      <td>8.44</td>\n","      <td>8.05</td>\n","      <td>8.38</td>\n","      <td>14579600.0</td>\n","      <td>733331654</td>\n","      <td>4</td>\n","      <td>-2.764493</td>\n","      <td>38</td>\n","      <td>0.837092</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3338</td>\n","      <td>3512</td>\n","      <td>4827</td>\n","      <td>52.36</td>\n","      <td>55.05</td>\n","      <td>24204</td>\n","      <td>12.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2017-01-03</th>\n","      <td>8.37</td>\n","      <td>10.00</td>\n","      <td>8.32</td>\n","      <td>9.73</td>\n","      <td>33625200.0</td>\n","      <td>851512055</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>120</td>\n","      <td>1.812371</td>\n","      <td>24</td>\n","      <td>-0.828760</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3981</td>\n","      <td>4672</td>\n","      <td>5687</td>\n","      <td>52.36</td>\n","      <td>55.05</td>\n","      <td>8985</td>\n","      <td>12.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2017-01-04</th>\n","      <td>9.71</td>\n","      <td>11.28</td>\n","      <td>9.56</td>\n","      <td>11.25</td>\n","      <td>41051200.0</td>\n","      <td>985515893</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>181</td>\n","      <td>2.519655</td>\n","      <td>54</td>\n","      <td>2.376397</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4484</td>\n","      <td>6338</td>\n","      <td>5507</td>\n","      <td>53.26</td>\n","      <td>54.57</td>\n","      <td>10199</td>\n","      <td>11.85</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2017-01-05</th>\n","      <td>11.29</td>\n","      <td>11.89</td>\n","      <td>9.40</td>\n","      <td>10.25</td>\n","      <td>41557400.0</td>\n","      <td>898497892</td>\n","      <td>78</td>\n","      <td>-2.816484</td>\n","      <td>170</td>\n","      <td>2.789309</td>\n","      <td>30</td>\n","      <td>2.119208</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4615</td>\n","      <td>5676</td>\n","      <td>5916</td>\n","      <td>53.77</td>\n","      <td>54.99</td>\n","      <td>13447</td>\n","      <td>11.67</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             open   high   low  close  ...  brent    EPU  vixClose  target\n","date                                   ...                                \n","2017-01-01   7.98   8.47  7.98   8.17  ...  55.05   2351     12.85       1\n","2017-01-02   8.17   8.44  8.05   8.38  ...  55.05  24204     12.85       1\n","2017-01-03   8.37  10.00  8.32   9.73  ...  55.05   8985     12.85       1\n","2017-01-04   9.71  11.28  9.56  11.25  ...  54.57  10199     11.85       0\n","2017-01-05  11.29  11.89  9.40  10.25  ...  54.99  13447     11.67       0\n","\n","[5 rows x 26 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Dv8O9lTMCIaT","colab_type":"code","outputId":"5c6ae2c0-9a20-4c62-e548-4b80bae3fc0a","executionInfo":{"status":"ok","timestamp":1591973967129,"user_tz":-120,"elapsed":998,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Constructing train and test set. Training set size hardcoded to be 90%\n","train_size = int(len(df) * 0.9)\n","test_size = len(df) - train_size\n","train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n","\n","print(train.shape, test.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(1094, 26) (122, 26)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cwPKMvBJ5nwK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFh3H4GUCNWZ","colab_type":"code","outputId":"d164dd36-e8f9-408a-9c2d-52c19a7dbfd6","executionInfo":{"status":"ok","timestamp":1591973967845,"user_tz":-120,"elapsed":539,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["#retrieving array names from dataset and removing target label from this array\n","features = df.columns.drop(\"target\")\n","#Fit scaler on train set so that model has no information on test data.\n","scaler = MinMaxScaler()\n","scaler = scaler.fit(train[features].to_numpy()) #fit data on train data\n","\n","train.loc[:, features] = scaler.transform(train[features].to_numpy()) #Scaling all features used and replacing in dataframe \n","test.loc[:, features] = scaler.transform(test[features].to_numpy()) #Scaling all features used (scaler fit on train data) and replacing in dataframe\n","\n","\n","#Warning is thrown because data in train and test set are overwritten by scaled data. both train and test data reference to parts of the 'original' pandas df. \n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[item] = s\n","/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[item] = s\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"07EGrhkeCS14","colab_type":"code","colab":{}},"source":["# Making function that will format input data to the right dimension\n","def datasetCreator(X, y):\n","  Xs, ys = [], []\n","  for i in range(len(X)):\n","    Xs.append(X.iloc[i:i+1].to_numpy())\n","    ys.append(y.iloc[i])\n","  return np.array(Xs), np.array(ys).squeeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KTRWvoyPCXj2","colab_type":"code","colab":{}},"source":["# Constructing the actual dataset by using the datasetCreator function\n","# Hardcoding target column name as it is always the same\n","X_train, y_train = datasetCreator(train.loc[:, features], train.loc[:, \"target\"])\n","#X_val, y_val = datasetCreator(val.loc[:, features], val.loc[:, target]) \n","X_test, y_test = datasetCreator(test.loc[:, features], test.loc[:, \"target\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTmNpDXOCbY4","colab_type":"code","outputId":"bd48cc39-3b38-40db-dc1d-32ab04a634cd","executionInfo":{"status":"ok","timestamp":1591973973895,"user_tz":-120,"elapsed":1267,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Making sure the dataframes have equal rows and have the expected dimension\n","#Small dataset = 14 columns, Big dataset = 25\n","print(X_train.shape, y_train.shape)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(1094, 1, 25) (1094,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eJRIvJC7Cn0p","colab_type":"code","outputId":"abc1c626-68e4-4f66-e202-8b157ed989bb","executionInfo":{"status":"ok","timestamp":1591977701428,"user_tz":-120,"elapsed":3676553,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":598}},"source":["def makeModel(X_train, y_train, config, config_accuracy):\n","  #reading the parameters used in the model\n","  n_units, n_epochs, n_batch, activation, dropout = config \n","\n","  model = keras.Sequential()\n","  model.add(keras.layers.LSTM(units = n_units, input_shape=(X_train.shape[1], X_train.shape[2])\n","                             #, return_sequences = True     #UNCOMMENT IN ORDER TO TEST 2ND LSTM LAYER!!\n","                              )) \n","  model.add(keras.layers.Dropout(dropout))\n","  #model.add(keras.layers.LSTM(units = 32))    #UNCOMMENT IN ORDER TO TEST 2ND LSTM LAYER!!\n","  #model.add(keras.layers.Dropout(dropout))    #UNCOMMENT IN ORDER TO TEST 2ND LSTM LAYER!!\n","  model.add(keras.layers.Dense(units = 1, activation = activation))\n","  model.compile(loss= \"binary_crossentropy\", optimizer= \"adam\", metrics = [\"accuracy\"])\n","  \n","  #fit model\n","  history = model.fit(X_train, y_train, epochs = n_epochs, batch_size = n_batch, validation_split = 0.10, shuffle = False, verbose = 0)\n","\n","  #storing the accuracy of the last epoch on both train and validation data\n","  config_accuracy[0].append(history.history[\"accuracy\"][-1])\n","  config_accuracy[1].append(history.history[\"val_accuracy\"][-1])\n","  \n","def model_configs():\n","\t#defining the parameters used\n","  n_units = [320, 384]\n","  n_epochs = [100, 150]\n","  n_batch = [32]\n","  activation = [\"sigmoid\", \"tanh\"]\n","  dropout = [0, 0.10, 0.15, 0.20]\n","\t# create configs\n","  configs = list()\n","  for i in n_units:\n","    for j in n_epochs:\n","      for k in n_batch:\n","        for l in activation:\n","          for m in dropout:\n","              cfg = [i, j, k, l, m]\n","              configs.append(cfg)\n","  print(\"Total configs: {}\".format(len(configs)))\n","  return configs\n","\n","configList = model_configs()\n","for config in configList:\n","  config_accuracy = [[],[]]\n","  for i in range(5):\n","    makeModel(X_train, y_train, config, config_accuracy)\n","  n_units, n_epochs, n_batch, activation, dropout  = config\n","  train_acc = statistics.mean(config_accuracy[0])\n","  val_acc = statistics.mean(config_accuracy[1])\n","  print(\"units: {}, epoch: {}, batch: {}, activation: {}, dropout: {}, ACC: {}, VAL_ACC: {}, ACC high: {}, ACC low: {}, VAL ACC high: {}, VAL ACC low: {}\".format(n_units, n_epochs, n_batch, activation, dropout, train_acc, val_acc, max(config_accuracy[0]), min(config_accuracy[0]),  max(config_accuracy[1]), min(config_accuracy[1])))\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Total configs: 32\n","units: 320, epoch: 100, batch: 32, activation: sigmoid, dropout: 0, ACC: 0.5908536314964294, VAL_ACC: 0.5472727417945862, ACC high: 0.5924796462059021, ACC low: 0.5894308686256409, VAL ACC high: 0.5545454621315002, VAL ACC low: 0.5363636612892151\n","units: 320, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.1, ACC: 0.5867885947227478, VAL_ACC: 0.5309090852737427, ACC high: 0.5904471278190613, ACC low: 0.5843495726585388, VAL ACC high: 0.5454545617103577, VAL ACC low: 0.5181818008422852\n","units: 320, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.15, ACC: 0.5770325064659119, VAL_ACC: 0.5199999809265137, ACC high: 0.5873983502388, ACC low: 0.5701219439506531, VAL ACC high: 0.5272727012634277, VAL ACC low: 0.5090909004211426\n","units: 320, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.2, ACC: 0.5762194991111755, VAL_ACC: 0.5181818008422852, ACC high: 0.5833333134651184, ACC low: 0.5691056847572327, VAL ACC high: 0.5181818008422852, VAL ACC low: 0.5181818008422852\n","units: 320, epoch: 100, batch: 32, activation: tanh, dropout: 0, ACC: 0.5363821148872375, VAL_ACC: 0.5436363637447357, ACC high: 0.5691056847572327, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.4545454680919647\n","units: 320, epoch: 100, batch: 32, activation: tanh, dropout: 0.1, ACC: 0.542479681968689, VAL_ACC: 0.5600000023841858, ACC high: 0.5630081295967102, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5454545617103577\n","units: 320, epoch: 100, batch: 32, activation: tanh, dropout: 0.15, ACC: 0.5416666746139527, VAL_ACC: 0.5600000023841858, ACC high: 0.559959352016449, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5363636612892151\n","units: 320, epoch: 100, batch: 32, activation: tanh, dropout: 0.2, ACC: 0.5422764301300049, VAL_ACC: 0.5745454430580139, ACC high: 0.5640243887901306, ACC low: 0.49593496322631836, VAL ACC high: 0.5909090638160706, VAL ACC low: 0.5545454621315002\n","units: 320, epoch: 150, batch: 32, activation: sigmoid, dropout: 0, ACC: 0.5782520294189453, VAL_ACC: 0.5418181777000427, ACC high: 0.5995935201644897, ACC low: 0.5558943152427673, VAL ACC high: 0.5636363625526428, VAL ACC low: 0.5272727012634277\n","units: 320, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.1, ACC: 0.5741869807243347, VAL_ACC: 0.5436363697052002, ACC high: 0.5792682766914368, ACC low: 0.5670731663703918, VAL ACC high: 0.5636363625526428, VAL ACC low: 0.5272727012634277\n","units: 320, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.15, ACC: 0.5689024329185486, VAL_ACC: 0.5472727417945862, ACC high: 0.5731707215309143, ACC low: 0.565040647983551, VAL ACC high: 0.5545454621315002, VAL ACC low: 0.5363636612892151\n","units: 320, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.2, ACC: 0.572357714176178, VAL_ACC: 0.5381818175315857, ACC high: 0.5833333134651184, ACC low: 0.5619918704032898, VAL ACC high: 0.5545454621315002, VAL ACC low: 0.5272727012634277\n","units: 320, epoch: 150, batch: 32, activation: tanh, dropout: 0, ACC: 0.5459349632263184, VAL_ACC: 0.5763636231422424, ACC high: 0.5792682766914368, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5636363625526428\n","units: 320, epoch: 150, batch: 32, activation: tanh, dropout: 0.1, ACC: 0.5601626038551331, VAL_ACC: 0.5490909099578858, ACC high: 0.5762194991111755, ACC low: 0.5406504273414612, VAL ACC high: 0.5727272629737854, VAL ACC low: 0.5181818008422852\n","units: 320, epoch: 150, batch: 32, activation: tanh, dropout: 0.15, ACC: 0.5648373961448669, VAL_ACC: 0.5600000023841858, ACC high: 0.5721544623374939, ACC low: 0.5579268336296082, VAL ACC high: 0.5727272629737854, VAL ACC low: 0.5363636612892151\n","units: 320, epoch: 150, batch: 32, activation: tanh, dropout: 0.2, ACC: 0.5453252077102662, VAL_ACC: 0.5618181824684143, ACC high: 0.5691056847572327, ACC low: 0.49593496322631836, VAL ACC high: 0.5909090638160706, VAL ACC low: 0.5454545617103577\n","units: 384, epoch: 100, batch: 32, activation: sigmoid, dropout: 0, ACC: 0.5902438759803772, VAL_ACC: 0.5545454621315002, ACC high: 0.5924796462059021, ACC low: 0.5873983502388, VAL ACC high: 0.5636363625526428, VAL ACC low: 0.5454545617103577\n","units: 384, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.1, ACC: 0.5768292546272278, VAL_ACC: 0.5418181896209717, ACC high: 0.5843495726585388, ACC low: 0.5680894255638123, VAL ACC high: 0.5545454621315002, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.15, ACC: 0.5802845358848572, VAL_ACC: 0.5309090852737427, ACC high: 0.5863820910453796, ACC low: 0.5691056847572327, VAL ACC high: 0.5454545617103577, VAL ACC low: 0.5181818008422852\n","units: 384, epoch: 100, batch: 32, activation: sigmoid, dropout: 0.2, ACC: 0.5756097435951233, VAL_ACC: 0.5309090733528137, ACC high: 0.5813007950782776, ACC low: 0.5701219439506531, VAL ACC high: 0.5454545617103577, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 100, batch: 32, activation: tanh, dropout: 0, ACC: 0.5406504034996032, VAL_ACC: 0.5672727227210999, ACC high: 0.5660569071769714, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5545454621315002\n","units: 384, epoch: 100, batch: 32, activation: tanh, dropout: 0.1, ACC: 0.5495935082435608, VAL_ACC: 0.5509090900421143, ACC high: 0.5579268336296082, ACC low: 0.5386179089546204, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5181818008422852\n","units: 384, epoch: 100, batch: 32, activation: tanh, dropout: 0.15, ACC: 0.534959352016449, VAL_ACC: 0.5727272629737854, ACC high: 0.5670731663703918, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5545454621315002\n","units: 384, epoch: 100, batch: 32, activation: tanh, dropout: 0.2, ACC: 0.5534552931785583, VAL_ACC: 0.5672727227210999, ACC high: 0.5619918704032898, ACC low: 0.5436992049217224, VAL ACC high: 0.6000000238418579, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 150, batch: 32, activation: sigmoid, dropout: 0, ACC: 0.572357714176178, VAL_ACC: 0.5327272653579712, ACC high: 0.5914633870124817, ACC low: 0.5548780560493469, VAL ACC high: 0.5545454621315002, VAL ACC low: 0.5181818008422852\n","units: 384, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.1, ACC: 0.57743901014328, VAL_ACC: 0.5381818294525147, ACC high: 0.5924796462059021, ACC low: 0.5640243887901306, VAL ACC high: 0.5454545617103577, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.15, ACC: 0.56747967004776, VAL_ACC: 0.5527272820472717, ACC high: 0.582317054271698, ACC low: 0.5579268336296082, VAL ACC high: 0.5636363625526428, VAL ACC low: 0.5363636612892151\n","units: 384, epoch: 150, batch: 32, activation: sigmoid, dropout: 0.2, ACC: 0.5737804770469666, VAL_ACC: 0.5509090900421143, ACC high: 0.5813007950782776, ACC low: 0.5619918704032898, VAL ACC high: 0.5636363625526428, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 150, batch: 32, activation: tanh, dropout: 0, ACC: 0.5520325183868409, VAL_ACC: 0.5763636231422424, ACC high: 0.5843495726585388, ACC low: 0.49593496322631836, VAL ACC high: 0.5909090638160706, VAL ACC low: 0.5454545617103577\n","units: 384, epoch: 150, batch: 32, activation: tanh, dropout: 0.1, ACC: 0.5451219558715821, VAL_ACC: 0.5654545307159424, ACC high: 0.5680894255638123, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5272727012634277\n","units: 384, epoch: 150, batch: 32, activation: tanh, dropout: 0.15, ACC: 0.5587398409843445, VAL_ACC: 0.5636363744735717, ACC high: 0.5680894255638123, ACC low: 0.5518292784690857, VAL ACC high: 0.6000000238418579, VAL ACC low: 0.5363636612892151\n","units: 384, epoch: 150, batch: 32, activation: tanh, dropout: 0.2, ACC: 0.5516260147094727, VAL_ACC: 0.5690909028053284, ACC high: 0.5752032399177551, ACC low: 0.49593496322631836, VAL ACC high: 0.581818163394928, VAL ACC low: 0.5545454621315002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v1MT9XcjxcK9","colab_type":"code","outputId":"d4978152-0865-40ab-9b94-5d42d5553add","executionInfo":{"status":"ok","timestamp":1591818503296,"user_tz":-120,"elapsed":723,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#print(config_accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.4359756112098694, 0.5813007950782776, 0.5924796462059021, 0.5945122241973877, 0.5934959053993225], [0.5909090638160706, 0.48181816935539246, 0.5, 0.4909090995788574, 0.4909090995788574]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ACCa9pcLLMc","colab_type":"code","outputId":"6a7ec276-1df0-4c69-fb7f-e76a281abfb4","executionInfo":{"status":"ok","timestamp":1591288740411,"user_tz":-120,"elapsed":715,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Possible baseline model that uses todays observation as tomorrows\n","\n","success = 0\n","failure = 0\n","for i in range(len(y_train)):\n","  print\n","  if i == len(y_train) - 1:\n","    print(\"success: {}\".format(success))\n","    print(\"failure: {}\".format(failure))\n","    break\n","  elif y_train[i] == y_train[i+1]:\n","    success += 1\n","  else:\n","    failure += 1\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["success: 491\n","failure: 602\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zIf_MLRrMaZ2","colab_type":"code","outputId":"c2506603-f47d-4d2e-c57d-923462f1981b","executionInfo":{"status":"ok","timestamp":1591288644765,"user_tz":-120,"elapsed":566,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(y_train[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9k3Y5xh6ofJ_","colab_type":"code","outputId":"9d0f1ae4-99cc-45be-bb04-a9a52650780b","executionInfo":{"status":"ok","timestamp":1591284055019,"user_tz":-120,"elapsed":635,"user":{"displayName":"David Meijer","photoUrl":"","userId":"17502820059935187751"}},"colab":{"base_uri":"https://localhost:8080/","height":529}},"source":["print(y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0\n"," 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1\n"," 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0\n"," 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n"," 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1\n"," 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0\n"," 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n"," 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1\n"," 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1\n"," 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1\n"," 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1\n"," 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0\n"," 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0\n"," 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1\n"," 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0\n"," 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1\n"," 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1\n"," 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0\n"," 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0\n"," 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1\n"," 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1\n"," 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1\n"," 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0\n"," 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0\n"," 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1\n"," 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0\n"," 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1\n"," 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0\n"," 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0\n"," 0 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0]\n"],"name":"stdout"}]}]}